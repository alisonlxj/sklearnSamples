'''
    岭回归
    Ridge 回归通过对系数的大    
    其中， α > 0 是控制系数收缩量的复杂性参数： α 的值越大，收缩量越大，模型对共线性的鲁棒性也更强。
'''
print('---')



from sklearn import linear_model

reg = linear_model.Ridge(alpha= .5)
reg.fit([[0,0], [0,0], [1,1]], [0,.1,1])

reg.coef_               # 线性斜率
reg.intercept_          # 截距


'''
    Plot Ridge coefficients as a function of the regularization
    岭系数对回归系数的影响
'''
print('https://scikit-learn.org/stable/auto_examples/linear_model/plot_ridge_path.html')




import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model

# X 是 10X10的 希尔伯特矩阵  元素A（i,j）=1/(i+j-1) 极度病态
X = 1. / ( np.arange(1, 11) + np.arange(0, 10)[:, np.newaxis] )
y = np.ones(10)

# 计算coef点路径
n_alphas = 200
alphas = np.logspace(-10, -2, n_alphas)         # 以10为底，-10到-2均分200份

coefs = []
for a in alphas:
    ridge = linear_model.Ridge(alpha = a, fit_intercept = False)
    ridge.fit(X, y)
    coefs.append(ridge.coef_)

# 结果展示

ax = plt.gca()
ax.plot(alphas, coefs)
ax.set_xscale('log')
ax.set_xlim(ax.get_xlim()[::-1])            
plt.xlabel('alpha')
plt.ylabel('weights')
plt.title('Ridge corfficients as a function of the regularization')
plt.axis('tight')
plt.show()


